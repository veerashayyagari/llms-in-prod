{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Goal : Implement Locality Sensitive Hashing (LSH) to perform ANN Similarity Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "- At it's core, LSH tries to reduces our search space by running vectors through a variety of hash functions and grouping vectors with similar hashes into same buckets.\n",
        "- Now if we have a search query vector, we only look in the buckets that have a similarity match to the query vector.\n",
        "- The concept is analogous to how dictionaries/hashmaps try to hash a given key. In general, these hash functions are such that they avoid collisions of keys(even though the keys are close to similar).In case of LSH hash functions, these functions try to increase collisions for vectors that might be similar so that they can grouped in the same bucket.\n",
        "- There are two widely used techniques:\n",
        "    - Traditional Technique : Uses shingling -> MinHashing -> LSH function\n",
        "    - Random Projection: Random Hyperplanes with DotProduct divides data points into multiple subsets -> Hamming Distance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "### Traditional Technique"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Shingling\n",
        "- k-Shingling or Shingling - is the process of converting a string of text into a set of 'shingles'.\n",
        "- In this process to create shingle, we move a window of size 'k' across the text. At each point we take a snapshot of the text to create one shingle\n",
        "- We place all these shingles into a set data structure to remove any duplicates."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "gather": {
          "logged": 1691123387319
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:29:47.2112918Z",
              "execution_start_time": "2023-08-04T04:29:46.8186481Z",
              "livy_statement_state": "available",
              "parent_msg_id": "3ec203a6-c47e-484e-acd9-a2049c4de7a2",
              "queued_time": "2023-08-04T04:29:46.7189589Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 38
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 38, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's take 3 sample strings to test\n",
        "\n",
        "a = \"A group of kids is playing in a yard and an old man is standing in the background\"\n",
        "b = \"The young boys are playing outdoors and the man is smiling nearby\"\n",
        "c = \"Two children are lying in the snow and are drawing angels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "gather": {
          "logged": 1691123389886
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:29:49.8521517Z",
              "execution_start_time": "2023-08-04T04:29:49.3914609Z",
              "livy_statement_state": "available",
              "parent_msg_id": "27ce4ddf-ef7b-4620-9f0e-347e4233d567",
              "queued_time": "2023-08-04T04:29:49.3088377Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 39
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 39, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# given a string, generate k window sized shingles and return unique shingles\n",
        "\n",
        "def gen_shingles(text: str, k: int=2):\n",
        "    shingles = [text[i:i+k] for i in range(len(text)-k)]\n",
        "    return set(shingles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "gather": {
          "logged": 1691123392448
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:29:52.4435322Z",
              "execution_start_time": "2023-08-04T04:29:51.8843501Z",
              "livy_statement_state": "available",
              "parent_msg_id": "c7380286-d0d3-4f10-80fc-e2d7c298cf11",
              "queued_time": "2023-08-04T04:29:51.7986264Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 40
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 40, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'d ', 'ay', ' y', 'th', 'he', 'ba', 'un', 'ta', ' k', 'ac', 'pl', 'of', 'gr', 'st', ' b', ' g', 'ma', ' m', 'ck', 'ds', 'la', 'ou', 'p ', 'an', ' p', 'f ', 'g ', 'nd', 'kg', 's ', 'a ', 'A ', ' s', 'di', 'ya', 'ld', 'in', ' a', ' i', 'ki', 'yi', 'ro', 'n ', 'ar', ' o', ' t', 'up', 'is', 'rd', 'ng', 'id', 'ol', 'e '}\n"
          ]
        }
      ],
      "source": [
        "a_shingles = gen_shingles(a)\n",
        "b_shingles = gen_shingles(b)\n",
        "c_shingles = gen_shingles(c)\n",
        "\n",
        "print(a_shingles)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Create Sparse Vectors to represent these shingles\n",
        "- First we will create a vocab set which is set of all the shingles in our test vocabulary\n",
        "- One Hot encode our shingles against this vocab set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1691123397348
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:29:57.329225Z",
              "execution_start_time": "2023-08-04T04:29:56.9521832Z",
              "livy_statement_state": "available",
              "parent_msg_id": "b4c7153a-0d7c-430d-a9b8-dfb3dd337a8b",
              "queued_time": "2023-08-04T04:29:56.874813Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 41
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 41, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create a vocab set \n",
        "\n",
        "vocab = a_shingles.union(b_shingles).union(c_shingles)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1691123401222
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:30:01.1253576Z",
              "execution_start_time": "2023-08-04T04:30:00.7349959Z",
              "livy_statement_state": "available",
              "parent_msg_id": "7482bbb5-081f-4735-861b-1eb8b8bbd48c",
              "queued_time": "2023-08-04T04:30:00.648819Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 42
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 42, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1]\n"
          ]
        }
      ],
      "source": [
        "# declare 3 lists for holding 1 hot encoding for a, b, c shingles\n",
        "a_1hot = []\n",
        "b_1hot = []\n",
        "c_1hot = []\n",
        "\n",
        "# iterate through elements in vocab and create 1 hot encoded vectors for a, b, c\n",
        "for v in vocab:\n",
        "    a_1hot.append(1 if v in a_shingles else 0)\n",
        "    b_1hot.append(1 if v in b_shingles else 0)\n",
        "    c_1hot.append(1 if v in c_shingles else 0)\n",
        "\n",
        "print(a_1hot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Minhashing\n",
        "\n",
        "- Allows us convert these sparse vectors to dense vectors\n",
        "- If we wanted to create a dense vector of size 30, we will use 30 minhash functions (one hash function for every position in the dense vector)\n",
        "- Minhash function is nothing but a random order of numbers between 1 and len(vocab) and then find the minimum number that aligns with a 1 in the sparse vector.\n",
        "- Since we wanted to produce 30 (or more) of these values to produce a signature (our dense vector), we need to repeat step 5 30 (or more) times to generate the signature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1691123407152
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:30:07.1578899Z",
              "execution_start_time": "2023-08-04T04:30:06.7929219Z",
              "livy_statement_state": "available",
              "parent_msg_id": "24e1670f-8336-449e-9706-2beb138639ee",
              "queued_time": "2023-08-04T04:30:06.7101114Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 43
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 43, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iteration: 1 -> index of 1 in minhash_vec: 77 -> value at 77 in sparse vector : 1 \n",
            "\n",
            "add 77 to the signature\n"
          ]
        }
      ],
      "source": [
        "from random import shuffle\n",
        "\n",
        "# generate a random order of numbers our first minhash_vec\n",
        "minhash_vec = list(range(1, len(vocab)+1))\n",
        "shuffle(minhash_vec)\n",
        "# print(minhash_vec)\n",
        "\n",
        "# let's find the smallest number, by iterating\n",
        "for i in range(1, len(vocab)+1):\n",
        "    # find index of i in minhash_vec\n",
        "    idx = minhash_vec.index(i)\n",
        "\n",
        "    print(f\"iteration: {i} -> index of {i} in minhash_vec: {idx} -> value at {idx} in sparse vector : {a_1hot[idx]} \\n\")\n",
        "\n",
        "    # does the sparse vector has '1' at this index?\n",
        "    if a_1hot[idx] == 1:\n",
        "        print(f'add {idx} to the signature')\n",
        "        break;\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Now that we saw how minhashing works, Let's create few functions to run through our samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "gather": {
          "logged": 1691123422256
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:30:22.2657527Z",
              "execution_start_time": "2023-08-04T04:30:21.8837284Z",
              "livy_statement_state": "available",
              "parent_msg_id": "c1ae1568-7e00-44e4-b7e3-37bea85f8bbe",
              "queued_time": "2023-08-04T04:30:21.8019518Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 44
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 44, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create the hash func that provides us the random order of numbers\n",
        "\n",
        "def create_hash_func(size: int):\n",
        "    hash_vec = list(range(1, size+1))\n",
        "    shuffle(hash_vec)\n",
        "    return hash_vec\n",
        "\n",
        "\n",
        "# create multiple such hashes one for each position in dense vector\n",
        "\n",
        "def build_minhash_function(vocab_size:int, dense_vector_size:int):\n",
        "    hash_vecs = []\n",
        "    for _ in range(dense_vector_size):\n",
        "        hash_vecs.append(create_hash_func(vocab_size))\n",
        "\n",
        "    return hash_vecs\n",
        "\n",
        "\n",
        "minhash_func = build_minhash_function(len(vocab), 50)\n",
        "\n",
        "# create signature or dense vectors for a given sparse vector using minhash function\n",
        "def create_minhash_signature(sparse_vec: list):\n",
        "    vocab_size = len(vocab)\n",
        "    signature = []\n",
        "\n",
        "    # iterate through each hash vector\n",
        "    for hash_vec in minhash_func:\n",
        "        for i in range(1, vocab_size+1):\n",
        "            idx = hash_vec.index(i)\n",
        "            if sparse_vec[idx] == 1:\n",
        "                signature.append(idx)\n",
        "                break;\n",
        "    \n",
        "    return signature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1691123426736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:30:26.6852766Z",
              "execution_start_time": "2023-08-04T04:30:26.3118524Z",
              "livy_statement_state": "available",
              "parent_msg_id": "26342428-251c-495e-935d-2eeba8e62697",
              "queued_time": "2023-08-04T04:30:26.2266513Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 45
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 45, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[71, 51, 71, 62, 29, 23, 29, 46, 29, 42, 47, 15, 31, 90, 32, 15, 73, 15, 20, 70, 23, 45, 70, 83, 84, 82, 30, 78, 28, 21, 1, 57, 82, 83, 71, 23, 83, 30, 83, 78, 67, 28, 81, 71, 75, 47, 80, 20, 73, 70]\n"
          ]
        }
      ],
      "source": [
        "# let's create minhash dense vectors for a_1hot, b_1hot and c_1hot sparse vectors\n",
        "\n",
        "a_sig = create_minhash_signature(a_1hot)\n",
        "b_sig = create_minhash_signature(b_1hot)\n",
        "c_sig = create_minhash_signature(c_1hot)\n",
        "\n",
        "print(c_sig)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Since we compressed down a sparse vector to a dense vector of size 30, let's compare the similarities using Jaccard distance to see if any info is lost due to this compression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "gather": {
          "logged": 1691123473303
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:31:13.2919471Z",
              "execution_start_time": "2023-08-04T04:31:12.9009818Z",
              "livy_statement_state": "available",
              "parent_msg_id": "2dc92207-e8f0-4b1e-be59-8d27581f5b70",
              "queued_time": "2023-08-04T04:31:12.8206288Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 47
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 47, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jaccard Distance for Original A and B 0.3972602739726027\n",
            "Jaccard Distance for Dense Signatures of A and B 0.28888888888888886\n",
            "\n",
            "\n",
            "Jaccard Distance for Original A and C 0.22666666666666666\n",
            "Jaccard Distance for Dense Signatures of A and C 0.18\n",
            "\n",
            "\n",
            "Jaccard Distance for Original B and C 0.2571428571428571\n",
            "Jaccard Distance for Dense Signatures of B and C 0.2391304347826087\n"
          ]
        }
      ],
      "source": [
        "def jaccard_distance(x: set, y: set):    \n",
        "    return len(x.intersection(y))/len(x.union(y))\n",
        "\n",
        "print(f'Jaccard Distance for Original A and B {jaccard_distance(a_shingles, b_shingles)}')\n",
        "print(f'Jaccard Distance for Dense Signatures of A and B {jaccard_distance(set(a_sig), set(b_sig))}')\n",
        "print('\\n')\n",
        "print(f'Jaccard Distance for Original A and C {jaccard_distance(a_shingles, c_shingles)}')\n",
        "print(f'Jaccard Distance for Dense Signatures of A and C {jaccard_distance(set(a_sig), set(c_sig))}')\n",
        "print('\\n')\n",
        "print(f'Jaccard Distance for Original B and C {jaccard_distance(b_shingles, c_shingles)}')\n",
        "print(f'Jaccard Distance for Dense Signatures of B and C {jaccard_distance(set(b_sig), set(c_sig))}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "#### Band and Hash\n",
        "- Split our signatures into bands.\n",
        "- Hash each band , if there is a collision place the entire vector in the same bucket\n",
        "- Why do we band the signatures ? Even if there is a part of the signature that has similarity with other vectors, we need to bucket them together. This will enable us to evaluate candidate pairs that have at least a sense of similarity instead of exact match.\n",
        "- Obviously this does increase the nbr of false positives, but tuning the band size should help us reduce them.\n",
        "- Since we have a 50 dimensional signature, if we split it into bands of size 10. It gives us the opportunity to check 5 such matches of sub-vectors.\n",
        "- ![Band and Hash](./resources/BandNHash.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "gather": {
          "logged": 1691123492986
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:31:32.8948906Z",
              "execution_start_time": "2023-08-04T04:31:32.5345376Z",
              "livy_statement_state": "available",
              "parent_msg_id": "0e1f881c-c568-4c8a-a994-c40060804a31",
              "queued_time": "2023-08-04T04:31:32.456352Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 48
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 48, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Let's split the vector into sub vectors\n",
        "def create_sub_vectors(signature_vec:list, subvec_size:int):\n",
        "    # we want the subvec_size to split equal subvectors with out leaving any data behind\n",
        "    assert(len(signature_vec)%subvec_size == 0)\n",
        "    sub_vectors = []\n",
        "    for i in range(0, len(signature_vec), subvec_size):\n",
        "        sub_vectors.append(signature_vec[i:i+subvec_size])\n",
        "\n",
        "    return sub_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "gather": {
          "logged": 1691123499526
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:31:39.5233843Z",
              "execution_start_time": "2023-08-04T04:31:39.1736316Z",
              "livy_statement_state": "available",
              "parent_msg_id": "2d2f1c2d-3a0d-4351-8a5c-364473470fdf",
              "queued_time": "2023-08-04T04:31:39.0973375Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 49
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 49, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "subvec bands for a [[6, 5, 71, 12, 29], [34, 63, 46, 29, 13], [56, 16, 27, 19, 6], [16, 21, 77, 20, 6], [29, 2, 19, 17, 5], [82, 16, 49, 28, 19], [64, 19, 53, 12, 71], [34, 12, 53, 18, 7], [67, 28, 10, 2, 69], [27, 80, 27, 49, 48]]\n",
            "subvec bands for b [[37, 66, 13, 58, 29], [34, 29, 46, 29, 13], [66, 15, 14, 19, 37], [15, 21, 50, 20, 66], [29, 2, 19, 37, 84], [82, 4, 49, 28, 19], [74, 37, 66, 66, 26], [54, 31, 37, 50, 19], [67, 28, 34, 2, 8], [22, 80, 74, 49, 9]]\n",
            "subvec bands for c [[71, 51, 71, 62, 29], [23, 29, 46, 29, 42], [47, 15, 31, 90, 32], [15, 73, 15, 20, 70], [23, 45, 70, 83, 84], [82, 30, 78, 28, 21], [1, 57, 82, 83, 71], [23, 83, 30, 83, 78], [67, 28, 81, 71, 75], [47, 80, 20, 73, 70]]\n"
          ]
        }
      ],
      "source": [
        "sig_bands_a = create_sub_vectors(a_sig, 5)\n",
        "sig_bands_b = create_sub_vectors(b_sig, 5)\n",
        "sig_bands_c = create_sub_vectors(c_sig, 5)\n",
        "\n",
        "print(f\"subvec bands for a {sig_bands_a}\")\n",
        "print(f\"subvec bands for b {sig_bands_b}\")\n",
        "print(f\"subvec bands for c {sig_bands_c}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1691123533932
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:32:13.9353112Z",
              "execution_start_time": "2023-08-04T04:32:13.5847569Z",
              "livy_statement_state": "available",
              "parent_msg_id": "3b9a32be-3646-4eae-a8c3-680841f3b6cb",
              "queued_time": "2023-08-04T04:32:13.5043126Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 50
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 50, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from itertools import combinations\n",
        "\n",
        "# Let's maintain buckets for each band (we have 10 bands)\n",
        "buckets = [{} for _ in range(10)]\n",
        "\n",
        "# take the list of bands, vec_indicator indicates the vector bands belong to\n",
        "def hash_sig_bands(bands: list, vec_indicator: int):\n",
        "    for i, band in enumerate(bands):\n",
        "        # perform a simple string join and use default dict hash in python\n",
        "        simple_hash = ','.join([str(i) for i in band])\n",
        "\n",
        "        # if the hash key is not present, create an empty list\n",
        "        if simple_hash not in buckets[i]:\n",
        "            buckets[i][simple_hash] = []\n",
        "\n",
        "        # append the vector indicator for this key\n",
        "        buckets[i][simple_hash].append(vec_indicator)\n",
        "\n",
        "\n",
        "def get_candidate_pairs():\n",
        "    candidates = []\n",
        "\n",
        "    # iterate through all buckets\n",
        "    for bucket in buckets:\n",
        "        # look for keys with multiple vector indicators (indicating a collision/hash match)\n",
        "        for key in bucket.keys():\n",
        "            if len(bucket[key]) > 1:\n",
        "                # add all possible vector pair combinations to candidates\n",
        "                candidates.extend(combinations(bucket[key], 2))\n",
        "    \n",
        "    # remove any duplicates\n",
        "    return set(candidates)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1691123537954
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "execution_finish_time": "2023-08-04T04:32:17.9307846Z",
              "execution_start_time": "2023-08-04T04:32:17.5665891Z",
              "livy_statement_state": "available",
              "parent_msg_id": "3524745c-1f33-44b0-8b8c-751419932b38",
              "queued_time": "2023-08-04T04:32:17.4660444Z",
              "session_id": "5",
              "session_start_time": null,
              "spark_jobs": {
                "jobs": [],
                "limit": 20,
                "numbers": {
                  "FAILED": 0,
                  "RUNNING": 0,
                  "SUCCEEDED": 0,
                  "UNKNOWN": 0
                },
                "rule": "ALL_DESC"
              },
              "spark_pool": "15d5176f-8c31-4590-b30b-49036d1913db",
              "state": "finished",
              "statement_id": 51
            },
            "text/plain": [
              "StatementMeta(15d5176f-8c31-4590-b30b-49036d1913db, 5, 51, Finished, Available)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "set()"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# hash all the signature bands\n",
        "\n",
        "hash_sig_bands(sig_bands_a, 1)\n",
        "hash_sig_bands(sig_bands_b, 2)\n",
        "hash_sig_bands(sig_bands_c, 3)\n",
        "\n",
        "# display candidate pairs that are similar\n",
        "get_candidate_pairs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Random Projection for LSH\n",
        "\n",
        "- ** Reduce the Dimensionality: ** We reduce the dimensionality of the sparse vector by using hyperplanes. \n",
        "    - Each hyperplane will divide the space into two halves.\n",
        "    - Any point on the +ve side of the hyperplane, the resulting dense vector is assigned a '1'\n",
        "    - Any point on the -ve side of the hyperplane, the resulting dense vector is assigned a '0'\n",
        "\n",
        "- ** How do we identify, which side the point is on: **\n",
        "    - Take a normal vector (any vector perpendicular to the plane)\n",
        "    - Perform a dotproduct between the normal vector and the data point\n",
        "    - If the normal vector and the data point are in the same direction , then the dot product is positive\n",
        "    - If the normal vector and the data point are in the opposite direction, then the dot product is negative.\n",
        "    - If the point is sitting on the edge of the hyperplane , then the dot product is zero. We can group it along with the negative dot product.    \n",
        "\n",
        "- ** Create Hashed Vectors: **\n",
        "    - Introduce multiple such Hyperplanes, if we want dense vector of 'n' dimensions. We will introduce 'n' such hyperplanes and then perform dotproduct to create an 'n' dimensional dense vector.\n",
        "    - Hash the dense vector and place all the vectors with similar hashes into buckets.\n",
        "\n",
        "- ** Search Complexity: **\n",
        "    - Now that we have bucketed all our vectors, let's consider how the search complexity is reduced.\n",
        "    - Given a query vector, gets converted to dense vector and then gets hashed following similar steps\n",
        "    - Hashed query vector will be compared against just the candidates in the bucket that match it's hash, thus reducing the search complexity from linear to sub-linear.\n",
        "    - With in the matching bucket, we compare the query vector with the candidates in the matching bucket. Then identify the closest matching candidates using Hamming distance.\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "kernelspec": {
      "display_name": "Synapse PySpark",
      "language": "Python",
      "name": "synapse_pyspark"
    },
    "language_info": {
      "codemirror_mode": "ipython",
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython",
      "version": "3.8.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
